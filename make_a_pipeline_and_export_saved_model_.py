# -*- coding: utf-8 -*-
"""Make a pipeline and export saved model .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1id-HNJWyW1Rf2x6cb03SKkNTdVOi1_JN

# Part 2.2
Train a model to detect MNIST
Be "creative with your model definitions
"""

# = Import things
import torch
import torch.nn as nn
import tensorflow as tf
import matplotlib.pyplot as plt

# = Definition
# Model definition
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Loss function definition
loss_function = tf.keras.losses.SparseCategoricalCrossentropy()

# Optimizer definition
optimizer = tf.keras.optimizers.Adam()

# Load data
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Compile the model
model.compile(optimizer=optimizer,
              loss=loss_function,
              metrics=['accuracy'])

losses_over_time = []
# Training loop
for epoch in range(5):  # Specify the number of epochs
    history = model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)
    losses_over_time.append(history.history['loss'][0])  # Append the training loss value

# Plot the loss_over_time graph
plt.plot(losses_over_time, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Save the model to .pth
model.save('/path/to/save/model')

"""# Part 2.3
Do write a lot of code snippets to make sure that things are correct.

Leave them here so that we could see that you have tried


"""

#I don't know how to create an annotations file effectively
import os
import csv
from google.colab import files

def generate_annotations_file(directory, output_file):
    # Get the list of file names in the directory
    file_names = sorted(os.listdir(directory))

    # Create a list to store image paths and labels
    annotations = [(os.path.join(directory, file), idx) for idx, file in enumerate(file_names)]

    # Write the annotations to a CSV file
    with open(output_file, 'w', newline='') as csvfile:
        fieldnames = ['image_path', 'label']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        for annotation in annotations:
            writer.writerow({'image_path': annotation[0], 'label': annotation[1]})

# Upload files to Colab
uploaded_files = files.upload()

# Use the uploaded file(s) in your code
directory_path = '.'  # Assuming the uploaded file is in the current directory
output_csv_file = 'annotations.csv'

generate_annotations_file(directory_path, output_csv_file)

from google.colab import drive
drive.mount('/content/drive')

"""## Dataset and DataLoader
Follow this link https://pytorch.org/tutorials/beginner/basics/data_tutorial.html
- Define the Dataset Class with 3 functions to get item
- Use the Dataloader in the training loop
- Iterate through the dataloader in the training loop
"""

# Define dataset class with 3 functions to get item
import os
import pandas as pd
from torchvision.io import read_image
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

class CustomImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = read_image(img_path)
        label = self.img_labels.iloc[idx, 1]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label

# Define paths to your training and test data directories
training_img_dir = r'C:\Users\User\OneDrive\Pictures\MNIST Dataset JPG format\MNIST Dataset JPG format\MNIST - JPG - training\0'
test_img_dir = r'C:\Users\User\OneDrive\Pictures\MNIST Dataset JPG format\MNIST Dataset JPG format\MNIST - JPG - testing\0'

# CustomImageDataset for training data
training_dataset = CustomImageDataset(img_dir=training_img_dir)

# CustomImageDataset for test data
test_dataset = CustomImageDataset(test_img_dir)

# Example: Accessing the first image and label in the training dataset
image, label = training_dataset[0]

# Display the image using matplotlib
plt.imshow(image.permute(1, 2, 0))  # Assuming image is a torch tensor with shape (C, H, W)
plt.title(f"Label: {label}")
plt.show()

# Use the Dataloader in the training loop
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)

# Iterate through the dataloader in the training loop
# Display image and label.
train_features, train_labels = next(iter(train_dataloader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {label}")